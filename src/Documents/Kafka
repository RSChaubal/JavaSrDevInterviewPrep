---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Ensure message delivery only to a failed consumer in a Kafka-based system with multiple consumers
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-> To ensure message delivery only to a failed consumer in a Kafka-based system with multiple consumers, you need to leverage Kafka's features and design choices, particularly around
consumer groups and offset management.

1. Consumer Groups and Rebalancing:
    - Kafka uses consumer groups to distribute partitions among consumers within a group.
    - If a consumer fails, Kafka will rebalance and assign its partitions to other consumers in the same group.
2. Manual Offset Commit (auto.commit=false):
    - Disable automatic offset committing. This gives you fine-grained control over when offsets are updated.
3. Custom Offset Management - Implement a strategy to store and update offsets. This can involve:
    - Storing the offset along with the processed data in a durable storage system (e.g., a database).
    - Using an atomic transaction to ensure both the offset update and data processing are either fully successful or completely rolled back.
    - Using Kafka's StoreOffset API for asynchronous offset commits if auto.commit is enabled.
4. Failure Detection and Recovery:
    - Implement mechanisms to detect consumer failures and trigger recovery actions. This could involve a health check or a heartbeat mechanism.
5. Retry and Recovery:
    - When a consumer restarts after a failure, it should retrieve the last committed offset from your custom offset storage.
    - It can then resume processing from that offset, effectively ensuring that it only processes messages that it failed to process previously.
6. Idempotency:
    - Ensure that your consumer logic is idempotent, meaning that reprocessing a message should not lead to unintended side effects or duplicate data.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Dead Letter Topic
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

A Dead Letter Queue (DLQ) or Dead Letter Topic (DLT) in Kafka is a special Kafka topic used to store messages that could not be processed by downstream consumers due to errors or failures.
Instead of dropping or silently discarding failed messages, a DLQ provides a place to inspect, reprocess, or analyze problematic messages, preventing them from blocking the main
processing pipeline.

-> Purpose of a Dead Letter Topic:
1) Error Handling:
    - DLQs are essential for robust error handling in Kafka-based streaming systems.
2) Error Analysis:
    - Failed messages in a DLQ can be reviewed by administrators or software to understand the cause of the failure.
3) Retry Logic:
    - A DLQ can be used to implement retry mechanisms, allowing messages to be re-processed after a delay or adjustment.
4) System Stability:
    - By isolating failed messages, DLQs prevent errors from cascading and disrupting the overall processing flow.

-> How it Works:
1) Failure Detection:
    - If a consumer encounters a failure (e.g., invalid data, processing error), it can be configured to route the message to a DLQ.
2. Message Routing:
    - Kafka Connect or other Kafka consumer applications can be configured to send failed messages to the designated DLQ topic.
3. Storage and Inspection:
    - The failed message is then stored in the DLQ, where it can be accessed and inspected by administrators or monitoring tools.
4. Reprocessing or Analysis:
    - Based on the analysis of the failed messages, decisions can be made regarding reprocessing, adjusting the data format, or correcting the application logic.

-> Benefits of Using a Dead Letter Topic:
1) Improved Error Handling:
    - Prevents the system from being overwhelmed by errors and allows for more graceful failure.
2) Enhanced Troubleshooting:
    - Provides a central repository for failed messages, making it easier to diagnose and resolve issues.
3) Increased Resilience:
    - Reduces the risk of cascading failures and ensures the overall stability of the system.
4) Data Integrity:
    - Ensures that even if some messages fail, the system continues to operate, and failed messages can be addressed later.

-> Example Scenario:
Imagine a system that processes user orders. If an order message has an invalid product ID, the consumer might encounter an error. Instead of dropping the message, the system
could route it to a DLQ. Administrators can then review the message, identify the invalid product ID, and take corrective action (e.g., fix the data, update the product catalog).

Error Handling via Dead Letter Queue in Apache Kafka - In essence, a Dead Letter Topic is a valuable tool for building reliable and resilient Kafka-based streaming pipelines.